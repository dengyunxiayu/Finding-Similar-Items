{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Home Assignment 1\n",
    "## Finding Similar Items: Textually Similar Documents\n",
    "### Group 11\n",
    "\n",
    "Boyu Xue (boyux@kth.se), Kristupas Bajarunas(kristupasbajarunas@gmail.com)\n",
    "\n",
    "\n",
    "### Description:\n",
    "\n",
    "You are to implement the stages of finding textually similar documents based on Jaccard similarity using the shingling, minhashing, and locality-sensitive hashing (LSH) techniques and corresponding algorithms. The implementation can be done using any big data processing framework, such as Apache Spark, Apache Flink, or no framework, e.g., in Java, Python, etc. To test and evaluate your implementation, write a program that uses your implementation to find similar documents in a corpus of 5-10 or more documents such as web pages or emails.\n",
    "\n",
    "The stages should be implemented as a collection of classes, modules, functions or procedures depending the framework and the language of your choice. Below, we give a description of sample classes that implement different stages of finding textually similar documents. You do not have to develop the exact same classes and data types as described below. Feel free to use data structures that suit you best.\n",
    "\n",
    "* A class Shingling that constructs k–shingles of a given length k (e.g., 10) from a given document, computes a hash value for each unique shingle, and represents the document in the form of an ordered set of its hashed k-shingles.\n",
    "* A class CompareSets that computes the Jaccard similarity of two sets of integers – two sets of hashed shingles.\n",
    "* A class MinHashing that builds a minHash signature (in the form of a vector or a set) of a given length n from a given set of integers (a set of hashed shingles).\n",
    "* A class CompareSignatures that estimates similarity of two integer vectors – minhash signatures – as a fraction of components, in which they agree.\n",
    "* (Optional task for extra 2 bonus) A class LSH that implements the LSH technique: given a collection of minhash signatures (integer vectors) and a similarity threshold t, the LSH class (using banding and hashing) finds all candidate pairs of signatures that agree on at least fraction t of their components.\n",
    "\n",
    "To test and evaluate scalability (the execution time versus the size of input dataset) of your implementation, write a program that uses your classes to find similar documents in a corpus of 5-10 documents. Choose a similarity threshold s (e.g., 0,8) that states that two documents are similar if the Jaccard similarity of their shingle sets is at least s. \n",
    "\n",
    "### Dataset\n",
    "\n",
    "#### Health News in Twitter Data Set\n",
    "\n",
    "#### Abstract: \n",
    "The data was collected in 2015 using Twitter API. This dataset contains health news from more than 15 major health news agencies such as BBC, CNN, and NYT.\n",
    "\n",
    "Data Set Characteristics: Text\n",
    "\n",
    "Number of Instances: 58000\n",
    "\n",
    "Area: Computer\n",
    "\n",
    "Attribute Characteristics: Real\n",
    "\n",
    "Number of Attributes: 25000\n",
    "\n",
    "Date Donated: 2018-02-19\n",
    "\n",
    "#### Source:\n",
    "\n",
    "Amir Karami (karami@sc.edu), University of South Carolina\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Health+News+in+Twitter\n",
    "\n",
    "#### Data Set Information:\n",
    "\n",
    "Each file is related to one Twitter account of a news agency. For example, bbchealth.txt is related to BBC health news. Each line contains tweet id|date and time|tweet. The separator is '|'. This text data has been used to evaluate the performance of topic models on short text data. However, it can be used for other tasks such as clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "#### 1. Import libraries and build-in functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "import numpy as np\n",
    "import codecs\n",
    "import time\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define the shingle function\n",
    "\n",
    "This function is used to:\n",
    "* Open files from a certain path (file_path).\n",
    "* Convert the files to shingle sets with a length (k) of 5.\n",
    "* Hash the shingles by using \"hash\" command of Python.\n",
    "* Return the set of hashed shingles by using the \"add\" command to add value of hashed shingle to the sets of shingles.\n",
    "\n",
    "In the file, each sentence includes a number and a date at the beginning, and a web address at the end. But we are not interested in the numbers, dates and web addresses. So we split the numbers, dates and web addresses by using \"line.split\" command. For example, in the sentence \"586266687948881921|Thu Apr 09 20:37:25 +0000 2015|Drugs need careful monitoring for expiry dates, pharmacists say http://www.cbc.ca/news/health/drugs-need-careful-monitoring-for-expiry-dates-pharmacists-say-1.3026749?cmp=rss\", only \"Drugs need careful monitoring for expiry dates, pharmacists say\" will be output to be hashed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_shingle(file_path,k=5):\n",
    "    start_time = time.time()\n",
    "    with open(file_path,'r',errors='ignore')as f:\n",
    "        hash_shingle=set()\n",
    "        for line in f:\n",
    "            line=line.split('|')[2].split(' http')[0]\n",
    "            for i in range(len(line)-k):\n",
    "                hash_shingle.add(hash(line[i:i+k]))\n",
    "    return hash_shingle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Define the Jaccard similarity function\n",
    "\n",
    "This function is used to:\n",
    "\n",
    "* Calculate the intersection and union of two sets(s1 and s2).\n",
    "* Divide the intersection by union and return the Jaccard similarity of the two sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacard_similarity(s1, s2):\n",
    "    return len(s1.intersection(s2)) / len(s1.union(s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Define the hash function\n",
    "\n",
    "The hash function can be expressed as (a*value of shingle+b) mod c. The coefficients a and b will be random number less than the maximum value of x (2^32-1=4294967295). c is a prime number(4294967311) slightly bigger than the maximum value of x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_function(function_index, value):\n",
    "    a = coefA[function_index]\n",
    "    b = coefB[function_index]\n",
    "    return (a * value + b) % nextPrime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Define the get signature function\n",
    "\n",
    "* For i in range of the number of hash function, calculate the returned value of hash function for the variable x (x will be the value of hash shingle from the sets of shingles)  by using the lambda function and the map function.\n",
    "\n",
    "* Add the minimum value of the signature to the end of the signature list by using the append method.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_signature(set_of_shingles):\n",
    "    signature = [] \n",
    "    for i in range(numH):\n",
    "        signature.append(min(map((lambda x: hash_function(i,x) ), set_of_shingles)))\n",
    "    return signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Define the locality sensitive hash (LSH) function\n",
    "\n",
    "1. Record the running time by setting the start time and the end time.\n",
    "2. Define finding similarity of LSH (find_sim_LSH) as a function of the number of bands(b) and the signature matrix. The number of rows(r) = number of hash functions/number of bands.\n",
    "3. Set the candidate pairs as a list.\n",
    "4. Build a dictionary named hash_table for the values of signatures by using the defaultdict command.\n",
    "5. For each band and for every document(doc_id) select the rows of that band and document with current_band.\n",
    "6. Add the band's signatures(current_band) to the bucket (current_hash) by using \"hash\" function of the tuple of signatures.\n",
    "7. Store the buckets(hash_table) by using \"append\" command.\n",
    "8. Return the candidate pairs from the bucket if the length of value in the bucket>1.\n",
    "9. Hash_table is reset for every band, candidate pairs are kept in memory, later candidate pairs are made into a set so that they do no repeat.\n",
    "9. For the candidate pairs, calculate the similarity based on their signature and the Jaccard similarity based on the hashed shingles.\n",
    "10. Calculate the implied threshold(t) by using the function t = (1/b)^1/r. The implied threshold should be similar to the desired threshold and controls false-positives/negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sim_LSH(b,signature):\n",
    "    start_time=time.time()\n",
    "    r=int(numH/b)\n",
    "    candidates = []\n",
    "    for band in range(0,b):\n",
    "        hash_table = defaultdict(list)\n",
    "        for doc_id in range(len(signature)):\n",
    "            start=band*r\n",
    "            end=(band+1)*r\n",
    "            current_band=signature[doc_id][start:end]\n",
    "            current_hash=hash(tuple(current_band))\n",
    "            hash_table[current_hash].append(doc_id)\n",
    "        for value in hash_table.values():\n",
    "            if len(value) > 1:\n",
    "                candidates += list(itertools.combinations(value, 2))  \n",
    "    candidates=set(candidates)\n",
    "    for pair in candidates:\n",
    "        sign1=signature[pair[0]]\n",
    "        sign2=signature[pair[1]]\n",
    "        count=0\n",
    "        for k in range(numH):\n",
    "            count = count + (sign1[k] == sign2[k])\n",
    "        print(\"Similarity of signature between {} and {} = {}. Jaccard={}\".\n",
    "              format(docNames[pair[0]],docNames[pair[1]],count/numH,\n",
    "                     jacard_similarity(hash_shingle_sets[pair[0]], hash_shingle_sets[pair[1]])))   \n",
    "    print(\"Time taken: %.8s seconds ---\" % (time.time() - start_time))\n",
    "    print('Implied threshold(1/b)^(1/r)={}'.format(pow((1/b),(1/r))))\n",
    "    Implied_threshold=pow((1/b),(1/r))\n",
    "    return Implied_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Look for the cadidate pairs with a given similarity threshold\n",
    "\n",
    "1. Find the cadidate pairs by calculate the similarity between the signatures and returns similar pairs if similarity is more than the given threshold.\n",
    "2. Inputs: threshold (thresh), signature_matrix (signature).\n",
    "3. This function records the time taken to find all similar pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity of signatures\n",
    "def find_sim_all(thresh,signature):\n",
    "    start_time = time.time()\n",
    "    for i in range(len(docNames)):\n",
    "        sig1 = signature[i]\n",
    "        for j in range(i+1,len(docNames)):\n",
    "            sig2=signature[j]\n",
    "            count = 0\n",
    "        # Count the number of positions in the minhash signature which are equal.\n",
    "            for k in range(0, numH):\n",
    "                count = count + (sig1[k] == sig2[k])\n",
    "            if (i!=j) and count/numH>thresh:\n",
    "\n",
    "                print(\"Similarity of signature between {} and {} = {}. Jaccard={}\".\n",
    "                      format(docNames[i],docNames[j],count/numH,\n",
    "                             jacard_similarity(hash_shingle_sets[i], hash_shingle_sets[j])))\n",
    "    print(\"Time taken: %.8s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Define file paths and some parameters which will be used in the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_folder = \"./data/\" \n",
    "# \"./Untitled Folder/\" here is the file path we want to deal with. \n",
    "docNames=os.listdir(\"data\") \n",
    "# \"./Untitled Folder/\" here is the file path we want to deal with. \n",
    "numH=100\n",
    "coefA=random.sample(range(2**32-1),numH)\n",
    "coefB=random.sample(range(2**32-1),numH)\n",
    "nextPrime=4294967311\n",
    "file_list = glob.glob(os.path.join(corpus_folder, \"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/cbchealth.txt',\n",
       " './data/cbcandreuters.txt',\n",
       " './data/cnnhealth.txt',\n",
       " './data/foxnewshealth.txt',\n",
       " './data/everydayhealth.txt',\n",
       " './data/nytimeshealth.txt',\n",
       " './data/bbchealth.txt',\n",
       " './data/reuters_health.txt',\n",
       " './data/msnhealthnews.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Call the hash_shingle function and transfer the documents in the file_list to hashed shingle sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_shingle_sets=list(map(hash_shingle,file_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Calculate the Jaccard similarity of shinglings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard similarity of shinglings between cbchealth.txt and cbcandreuters.txt = 0.5286752042679373 \n",
      "Jaccard similarity of shinglings between cbchealth.txt and cnnhealth.txt = 0.24989234838698338 \n",
      "Jaccard similarity of shinglings between cbcandreuters.txt and cnnhealth.txt = 0.24020114840044224 \n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    shingle1 = hash_shingle_sets[i]\n",
    "    for j in range(i+1,3):\n",
    "        shingle2=hash_shingle_sets[j]\n",
    "        print(\"Jaccard similarity of shinglings between {} and {} = {} \".\n",
    "              format(docNames[i],docNames[j],jacard_similarity(shingle1, shingle2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Call the get_signature function and transfer the hashed shingle sets to signature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "signature_matrix = list(map(get_signature , hash_shingle_sets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.Call the find_sim_LSH function and return the candidate pairs, as well as their similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.000267 seconds ---\n",
      "Implied threshold(1/b)^(1/r)=0.5492802716530588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5492802716530588"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_sim_LSH(20,signature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Find the cadidate pairs with a given similarity threshold by calculating the similarity between the signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of signature between cbchealth.txt and cbcandreuters.txt = 0.51. Jaccard=0.5286752042679373\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8109a07bb768>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_sim_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msignature_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-c564d297dd52>\u001b[0m in \u001b[0;36mfind_sim_all\u001b[0;34m(thresh, signature)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msig1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocNames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0msig2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Count the number of positions in the minhash signature which are equal.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "find_sim_all(0.5,signature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "\n",
    "1. https://mccormickml.com/2015/06/12/minhash-tutorial-with-python-code/\n",
    "2. Rajaraman, Anand, and Jeffrey David Ullman. Mining of massive datasets. Cambridge University Press, 2011."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
